{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Modules \n",
    "import cv2\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 480, 3)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# reading Image \n",
    "img=cv2.imread('gg.jpg')  # '0' will give  grayscale image and '1' will give colored image \n",
    "#print(img)             # numpy array - as image is converted into numpay arrays \n",
    "print(img.shape)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing image \n",
    "cv2.imshow('face',img)\n",
    "cv2.waitKey(10)         # image will be shown for 0 miliseconds \n",
    "cv2.destroyAllWindows() # closes all windows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(2000)      # image will be shown for 20000 miliseconds \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the image \n",
    "resized_image=cv2.resize(img,(int(img.shape[1]*2),int(img.shape[0]*2)))   #double the image size \n",
    "cv2.imshow('resize',resized_image)\n",
    "cv2.waitKey(2000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datecting Face using cascade classifier(contains predefined face features)\n",
    "face_cascade=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')   #creating a cascade classifier \n",
    "\n",
    "\n",
    "# reading the image \n",
    "img=cv2.imread('gg.jpg')\n",
    "\n",
    "\n",
    "#Reading the image as a grayscale image \n",
    "gray_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)      #converting image into grayscale image \n",
    "\n",
    "\n",
    "#Search the coordinates of the image \n",
    "faces=face_cascade.detectMultiScale(gray_img,scaleFactor=1.05,minNeighbors=5)      \n",
    "#'detectMultiScale' is the method to search the face rectangle coordinates \n",
    "#'scalefactor' decreases the shape value by 5% ,until the face is found ,\n",
    "#Smaller the scaleFactor greater the accuracy \n",
    "\n",
    "\n",
    "#Drawing a rectange \n",
    "for x,y,w,h in faces:\n",
    "    img=cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    # rectange is the method to draw rectange \n",
    "    #x,y,x+w,y+h are the coordinates of the rectange \n",
    "    #(0,255,0) is the BGR value of the ractange   ---- Range=(0 to 255)   \n",
    "    # 3 is the width of the rectangle \n",
    "    \n",
    "\n",
    "cv2.imshow('face',img)\n",
    "cv2.waitKey(2000)\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturing video from the camera \n",
    "video=cv2.VideoCapture(0)  # Method to create videocapture object.It will trigger the camera \n",
    "                           #Either give path to the video file or use numbers.Numbers specify that\n",
    "                           # you will be using webcam to capture video. '0' means the webcam ,'1' \n",
    "                           #  means camera(external) other than webcam connectd to your PC.\n",
    "\n",
    "            \n",
    "video.release()         # This will release the camera in some miliseconds.\n",
    "\n",
    "# Running just this code will switch on the camera light for a second. \n",
    "# so here we have to add a time delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time              # time Module \n",
    "video=cv2.VideoCapture(0)\n",
    "\n",
    "time.sleep(3)          # This will stop the script for 3 seconds \n",
    "\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[[[165 166 170]\n",
      "  [162 163 167]\n",
      "  [172 168 169]\n",
      "  ...\n",
      "  [141 133 117]\n",
      "  [121 129 118]\n",
      "  [124 132 121]]\n",
      "\n",
      " [[157 165 168]\n",
      "  [157 165 168]\n",
      "  [161 165 166]\n",
      "  ...\n",
      "  [137 129 113]\n",
      "  [121 127 116]\n",
      "  [126 132 121]]\n",
      "\n",
      " [[154 165 165]\n",
      "  [156 167 167]\n",
      "  [158 167 167]\n",
      "  ...\n",
      "  [132 128 113]\n",
      "  [122 126 113]\n",
      "  [126 130 117]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[181 183 177]\n",
      "  [185 187 181]\n",
      "  [186 189 180]\n",
      "  ...\n",
      "  [ 46  61  81]\n",
      "  [ 45  60  80]\n",
      "  [ 45  60  80]]\n",
      "\n",
      " [[179 183 177]\n",
      "  [183 187 181]\n",
      "  [177 187 182]\n",
      "  ...\n",
      "  [ 49  63  81]\n",
      "  [ 49  62  82]\n",
      "  [ 47  60  80]]\n",
      "\n",
      " [[172 183 176]\n",
      "  [173 184 177]\n",
      "  [169 184 178]\n",
      "  ...\n",
      "  [ 51  64  79]\n",
      "  [ 49  60  80]\n",
      "  [ 44  55  75]]]\n"
     ]
    }
   ],
   "source": [
    "# Adding windows that shows  the video \n",
    "\n",
    "video=cv2.VideoCapture(0)\n",
    "\n",
    "check,frame =video.read()        #'check' is bool data type, returns true if the python is able \n",
    "                                  # capture the videoCapture object \n",
    "                                 #'frame' is the numpy array, it represents the first image that \n",
    "                                  # video captures.\n",
    "        \n",
    "print(check)\n",
    "print(frame)\n",
    "        \n",
    "time.sleep(3)\n",
    "\n",
    "cv2.imshow('video',frame)      # it will display the first frame of the videocapture object \n",
    "cv2.waitKey(2000)\n",
    "\n",
    "video.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281\n"
     ]
    }
   ],
   "source": [
    "# In order to capture the video we will be using the while loop. While condition is such that,\n",
    "# until 'check' is true,Python will display the frames.\n",
    "\n",
    "video=cv2.VideoCapture(0)\n",
    "\n",
    "a=1\n",
    "\n",
    "while True:\n",
    "    a=a+1\n",
    "    check,frame=video.read()\n",
    "    \n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    cv2.imshow('capturing',gray)\n",
    "    \n",
    "    key=cv2.waitKey(1)         # This will generate a new frame after every miliseconds \n",
    "    \n",
    "    if key==ord('q'):          # when you press q the window will get destroyed \n",
    "        break\n",
    "    \n",
    "    \n",
    "print(a)           # print the number of frames \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting face in video \n",
    "\n",
    "face_cascade=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "video=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    check,frame=video.read()\n",
    "    \n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces=face_cascade.detectMultiScale(gray,scaleFactor=1.05,minNeighbors=5)\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(20,25,200),2)\n",
    "        \n",
    "    \n",
    "    cv2.imshow('capturing',frame)\n",
    "    \n",
    "    key=cv2.waitKey(1)\n",
    "    \n",
    "    if key==ord('q'):\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Face Recognizer \n",
    "\n",
    "import cv2\n",
    "import os          # os module for reading training data directories and paths \n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As OpenCV face recognizer accepts labels as integers so we need to define a mapping between \n",
    "# integer labels and persons actual names so below I am defining a mapping of persons integer\n",
    "# labels and their respective names.\n",
    "\n",
    "#there is no label 0 in our training data so subject name for index/label 0 is empty\n",
    "subjects=['','Aalia_Bhatt','Aamir_khan','Ranvir_singh','Sharukh_Khan','Taapsee_Pannu']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the data \n",
    "\n",
    "# Function to detect face using opencv \n",
    "def detect_face(img):\n",
    "    \n",
    "    gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)   #Converting to grayscale\n",
    "    \n",
    "    face_cascade=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    faces=face_cascade.detectMultiScale(gray,scaleFactor=1.05,minNeighbors=5)\n",
    "    \n",
    "    #if no face is detected then return original image \n",
    "    if(len(faces)==0):\n",
    "        return None,None\n",
    "    \n",
    "    # extract face area \n",
    "    (x ,y,w,h)=faces[0]\n",
    "    \n",
    "    #return only face part \n",
    "    return gray[y:y+w,x:x+h], faces[0]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will read all persons' training images, detect face from each image\n",
    "#and will return two lists of exactly same size, one list \n",
    "# of faces and another list of labels for each face\n",
    "\n",
    "def prepare_training_data(data_folder_path):\n",
    "    \n",
    "    # get the directories(one directory for each subject) in data folder \n",
    "    dirs=os.listdir(data_folder_path)\n",
    "    \n",
    "    #list to hold all subject faces \n",
    "    faces=[]\n",
    "    \n",
    "    # list to hold labels for all subject faces \n",
    "    labels=[]\n",
    "    \n",
    "    for dir_name in dirs:\n",
    "        \n",
    "        #our subject directories start with letter 's' so\n",
    "        #ignore any non-relevant directories if any\n",
    "        if not dir_name.startswith('s'):\n",
    "            continue\n",
    "        \n",
    "        \n",
    "         #extract label number of subject from dir_name\n",
    "        #format of dir name = slabel\n",
    "        #, so removing letter 's' from dir_name will give us label\n",
    "        label=int(dir_name.replace('s',''))\n",
    "        \n",
    "        #built path of directory containing images for current subject \n",
    "        # sample subject_dir_path='training-data/s1'\n",
    "        subject_dir_path=data_folder_path+'/'+dir_name \n",
    "        \n",
    "        #get the images names  that are inside the subject directory \n",
    "        subject_images_names= os.listdir(subject_dir_path)\n",
    "        \n",
    "        # go through each image name ,read image ,detect face ,and add face to the list of faces \n",
    "        for image_name in subject_images_names:\n",
    "            \n",
    "            #build image path \n",
    "            #same image path=training-data/s1/1.pgm\n",
    "            image_path=subject_dir_path+'/'+image_name \n",
    "            \n",
    "            #read image \n",
    "            image=cv2.imread(image_path)\n",
    "            \n",
    "            #display an image window to show the image \n",
    "            cv2.imshow('training on image ....',image)\n",
    "            cv2.waitKey(100)\n",
    "            \n",
    "            #detect face using function detect_face \n",
    "            face,rect=detect_face(image)\n",
    "            \n",
    "            if face is not None:\n",
    "                #add face to faces list \n",
    "                faces.append(face)\n",
    "                #add label for this face \n",
    "                labels.append(label)\n",
    "                \n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    return faces,labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total faces 49\n",
      "total labels 49\n"
     ]
    }
   ],
   "source": [
    "# prepare the trainingg data \n",
    "# data will be in two list of same size \n",
    "# one will contain faces and other will contain labels for each face \n",
    "\n",
    "faces,labels=prepare_training_data('training_data')\n",
    "\n",
    "print('total faces',len(faces))\n",
    "print('total labels',len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traning face recognizor \n",
    "\n",
    "#OpenCV has three face recognizor ,we can use any one of them \n",
    "#1-EigenFace Recognizer\n",
    "#2-FisherFace Recognizer\n",
    "#3-LocalBinaryPatternsHistogram(LBPH) Recognizer \n",
    "\n",
    "# create the LBPH face recognizor \n",
    "face_recognizer=cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "#train face recognizor \n",
    "face_recognizer.train(faces,np.array(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to draw rectangle on image \n",
    "def draw_rectangle(img,rect):\n",
    "    (x,y,w,h)=rect\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \n",
    "    \n",
    "#function to draw text on image \n",
    "def draw_text(img,text,x,y):\n",
    "    cv2.putText(img,text,(x,y),cv2.FONT_HERSHEY_PLAIN,1.5,(0,255,0),2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that recognizes the test image \n",
    "def predict(test_image):\n",
    "    img=test_image.copy()\n",
    "    \n",
    "    #detect face from the image \n",
    "    face,rect=detect_face(img)\n",
    "    \n",
    "    #predict the face using our face recognizer \n",
    "    label=face_recognizer.predict(face)\n",
    "    \n",
    "    # get name of the respective label returned by face recognizer \n",
    "    label_text=subjects[label[0]]\n",
    "    \n",
    "    \n",
    "    #draw a rectangle around the face detected \n",
    "    draw_rectangle(img,rect)\n",
    "    \n",
    "    # draw name of the predicted image \n",
    "    draw_text(img,label_text,rect[0],rect[1]-5)\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting image ....\n",
      "prediction complete\n"
     ]
    }
   ],
   "source": [
    "#predicting image \n",
    "print('predicting image ....')\n",
    "\n",
    "#load test images \n",
    "test_img1=cv2.imread('test_data/test3.jpg')\n",
    "test_img2=cv2.imread('test_data/test4.jpg')\n",
    "\n",
    "# perform a prediction \n",
    "predicted_img1=predict(test_img1)\n",
    "predicted_img2=predict(test_img2)\n",
    "\n",
    "print('prediction complete')\n",
    "\n",
    "#display both images \n",
    "cv2.imshow('test1',predicted_img1)\n",
    "cv2.imshow('test2',predicted_img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
